{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "collab_donkeycar_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlD03JYf1kgC",
        "colab_type": "text"
      },
      "source": [
        "# Install TensorFlow "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDftbH-Y06d7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Newest nightly version. Didn't work for training. Missing 'ConfigProto' library \n",
        "#!pip uninstall tensorflow\n",
        "!pip install tensorflow-gpu==1.13.1\n",
        "# Install tensor flow gpu in case it's not installed\n",
        "\n",
        "#!pip install tensorflow-gpu==1.14.0\n",
        "# Check if TF installed\n",
        "#!pip install tensorflow==2.0.0-rc1 \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao5qKx975yjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 -c 'import tensorflow as tf; print(tf.__version__)'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJn-5Ty9I5To",
        "colab_type": "code",
        "outputId": "36010180-de0f-48ca-e5f6-b0536dadb3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "# Check if GPU in computer\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxpSi9MJ2751",
        "colab_type": "text"
      },
      "source": [
        "# Installation DonkeyCar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtPjCiq72GZ2",
        "colab_type": "code",
        "outputId": "892eb6b1-36f6-4824-e2ad-c1a495fbfda6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/autorope/donkeycar.git\n",
        "%cd /content/donkeycar\n",
        "!git checkout dev\n",
        "!pip3 install -e .[pc]\n",
        "!donkey createcar --path /content/d2/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'donkeycar'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 11700 (delta 8), reused 15 (delta 8), pack-reused 11682\u001b[K\n",
            "Receiving objects: 100% (11700/11700), 59.79 MiB | 46.70 MiB/s, done.\n",
            "Resolving deltas: 100% (7319/7319), done.\n",
            "/content/donkeycar\n",
            "Already on 'dev'\n",
            "Your branch is up to date with 'origin/dev'.\n",
            "Obtaining file:///content/donkeycar\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (1.17.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (6.2.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (0.6.2)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (4.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (2.21.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (2.8.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (0.2.3.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (0.25.3)\n",
            "Requirement already satisfied: PrettyTable in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (0.7.2)\n",
            "Collecting paho-mqtt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/11/1dd5c70f0f27a88a3a05772cd95f6087ac479fac66d9c7752ee5e16ddbbc/paho-mqtt-1.5.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (3.1.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.1) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.1) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->donkeycar==3.1.1) (1.12.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.1) (4.4.1)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.1) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.1) (4.28.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->donkeycar==3.1.1) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->donkeycar==3.1.1) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->donkeycar==3.1.1) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->donkeycar==3.1.1) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->donkeycar==3.1.1) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->donkeycar==3.1.1) (42.0.2)\n",
            "Building wheels for collected packages: paho-mqtt\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paho-mqtt: filename=paho_mqtt-1.5.0-cp36-none-any.whl size=61416 sha256=c0b0b5453d06b1aa07ff7874e2fae0afbc34d095b9fbaccd5d881b7191f8bedf\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/94/6c/8474137cb7a5a3e001d70a22c8ff919caee69435376bccce79\n",
            "Successfully built paho-mqtt\n",
            "Installing collected packages: paho-mqtt, donkeycar\n",
            "  Running setup.py develop for donkeycar\n",
            "Successfully installed donkeycar paho-mqtt-1.5.0\n",
            "using donkey v3.1.1 ...\n",
            "Creating car folder: /content/d2/\n",
            "making dir  /content/d2/\n",
            "Creating data & model folders.\n",
            "making dir  /content/d2/models\n",
            "making dir  /content/d2/data\n",
            "making dir  /content/d2/logs\n",
            "Copying car application template: complete\n",
            "Copying car config defaults. Adjust these before starting your car.\n",
            "Copying train script. Adjust these before starting your car.\n",
            "Copying my car config overrides\n",
            "Donkey setup complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvDElwzW5HXq",
        "colab_type": "text"
      },
      "source": [
        "# Upload files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsXBjegJJhto",
        "colab_type": "text"
      },
      "source": [
        "**From PC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVGv9OIS5uj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for Zipping in pc with linux\n",
        "#zip -r  ~/donkeycar/d2/data/data.zip *\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "if(os.path.exists(\"/content/data.zip\")):\n",
        "   os.remove(\"/content/data.zip\")\n",
        "if(os.path.exists(\"/content/d2/data/data.zip\")):\n",
        "   os.remove(\"/content/d2/data/data.zip\")\n",
        "   \n",
        "uploaded = files.upload()\n",
        "\n",
        "WORK_FOLDER = \"/content/d2/data/\"\n",
        "if(os.path.exists(WORK_FOLDER) == False):\n",
        "  os.makedirs(WORK_FOLDER)\n",
        "\n",
        "!mv /content/data.zip /content/d2/data/\n",
        "%cd /content/d2/data/\n",
        "!unzip -o data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rq_f3bIj9R5k",
        "outputId": "005bdf3a-6f57-4557-9e54-eea9ce951659",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#for Zipping in pc with linux\n",
        "#zip -r  ~/donkeycar/d2/data/data.zip *\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "if(os.path.exists(\"/content/data.zip\")):\n",
        "   os.remove(\"/content/data.zip\")\n",
        "if(os.path.exists(\"/content/d2/data/data.zip\")):\n",
        "   os.remove(\"/content/d2/data/data.zip\")\n",
        "   \n",
        "uploaded = files.upload()\n",
        "\n",
        "WORK_FOLDER = \"/content/d2/data/\"\n",
        "if(os.path.exists(WORK_FOLDER) == False):\n",
        "  os.makedirs(WORK_FOLDER)\n",
        "\n",
        "#!mv /content/data.zip /content/d2/data/\n",
        "#%cd /content/d2/data/\n",
        "#!unzip -o data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d5c83231-dba8-4872-a417-cc6afd3013c7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d5c83231-dba8-4872-a417-cc6afd3013c7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving todo to todo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdscHYArJoOM",
        "colab_type": "text"
      },
      "source": [
        "**From Github**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkBKH1pVKfoG",
        "colab_type": "code",
        "outputId": "af4601d6-946f-44c6-cfeb-a07c53101b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "%cd /content/d2/data/\n",
        "!rm -r * #Erase in case of old data \n",
        "!git clone https://github.com/JuanFuriaz/donkey_car_data.git # get the latest data\n",
        "!mv /content/d2/data/donkey_car_data/* /content/d2/data/    #\n",
        "!rm -r donkey_car_data\n",
        "!rm -r tubs-bigline-december/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/d2/data\n",
            "Cloning into 'donkey_car_data'...\n",
            "remote: Enumerating objects: 40174, done.\u001b[K\n",
            "remote: Total 40174 (delta 0), reused 0 (delta 0), pack-reused 40174\u001b[K\n",
            "Receiving objects: 100% (40174/40174), 120.24 MiB | 40.55 MiB/s, done.\n",
            "Resolving deltas: 100% (14036/14036), done.\n",
            "Checking out files: 100% (34526/34526), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7FxYfiOBK-N",
        "colab_type": "text"
      },
      "source": [
        "# Trainig"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o21x655L-C3M",
        "colab_type": "code",
        "outputId": "cc34268b-58d6-4e6b-c639-a9ac5c232b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/d2/manage.py train --type linear --model /content/d2/models/lin_aug2_collab.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using donkey v3.1.1 ...\n",
            "loading config file: /content/d2/config.py\n",
            "loading personal config over-rides\n",
            "\n",
            "config loaded\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "2020-01-19 17:19:39.842621: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-01-19 17:19:39.948638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-19 17:19:39.949368: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1cef4a0 executing computations on platform CUDA. Devices:\n",
            "2020-01-19 17:19:39.949404: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-01-19 17:19:39.950951: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-01-19 17:19:39.951166: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1cef340 executing computations on platform Host. Devices:\n",
            "2020-01-19 17:19:39.951196: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2020-01-19 17:19:39.951337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.52GiB\n",
            "2020-01-19 17:19:39.951364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2020-01-19 17:19:39.952214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-01-19 17:19:39.952236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2020-01-19 17:19:39.952246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2020-01-19 17:19:39.952336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14125 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "\"get_model_by_type\" model Type is: linear\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "training with model type <class 'donkeycar.parts.keras.KerasLinear'>\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_in (InputLayer)             (None, 120, 160, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 58, 78, 24)   1824        img_in[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 58, 78, 24)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 27, 37, 32)   19232       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 27, 37, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 12, 17, 64)   51264       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 12, 17, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 15, 64)   36928       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 10, 15, 64)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 13, 64)    36928       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 8, 13, 64)    0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flattened (Flatten)             (None, 6656)         0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          665700      flattened[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 100)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 50)           5050        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 50)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs0 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs1 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 817,028\n",
            "Trainable params: 817,028\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "found 0 pickles writing json records and images in tub /content/d2/data/tub4_1_style_aug_01\n",
            "found 0 pickles writing json records and images in tub /content/d2/data/tub2_1_style_aug_01\n",
            "found 0 pickles writing json records and images in tub /content/d2/data/tub4_0-5_style_aug_01\n",
            "found 0 pickles writing json records and images in tub /content/d2/data/tub_4_19-12-14\n",
            "found 0 pickles writing json records and images in tub /content/d2/data/tub_2_19-12-22\n",
            "found 0 pickles writing json records and images in tub /content/d2/data/tub2_0.5_style_aug_01\n",
            "/content/d2/data/tub4_1_style_aug_01\n",
            "/content/d2/data/tub2_1_style_aug_01\n",
            "/content/d2/data/tub4_0-5_style_aug_01\n",
            "/content/d2/data/tub_4_19-12-14\n",
            "/content/d2/data/tub_2_19-12-22\n",
            "/content/d2/data/tub2_0.5_style_aug_01\n",
            "collating 15621 records ...\n",
            "train: 12496, val: 3125\n",
            "total records: 15621\n",
            "steps_per_epoch 97\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "2020-01-19 17:19:44.616357: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 0.2529 - n_outputs0_loss: 0.2504 - n_outputs1_loss: 0.0025\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.25291, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 21s 213ms/step - loss: 0.3622 - n_outputs0_loss: 0.3556 - n_outputs1_loss: 0.0066 - val_loss: 0.2529 - val_n_outputs0_loss: 0.2504 - val_n_outputs1_loss: 0.0025\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.2014 - n_outputs0_loss: 0.2001 - n_outputs1_loss: 0.0013\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.25291 to 0.20141, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 56ms/step - loss: 0.2370 - n_outputs0_loss: 0.2326 - n_outputs1_loss: 0.0043 - val_loss: 0.2014 - val_n_outputs0_loss: 0.2001 - val_n_outputs1_loss: 0.0013\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1612 - n_outputs0_loss: 0.1600 - n_outputs1_loss: 0.0012\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.20141 to 0.16122, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.1881 - n_outputs0_loss: 0.1851 - n_outputs1_loss: 0.0029 - val_loss: 0.1612 - val_n_outputs0_loss: 0.1600 - val_n_outputs1_loss: 0.0012\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1549 - n_outputs0_loss: 0.1536 - n_outputs1_loss: 0.0012\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.16122 to 0.15487, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.1617 - n_outputs0_loss: 0.1593 - n_outputs1_loss: 0.0025 - val_loss: 0.1549 - val_n_outputs0_loss: 0.1536 - val_n_outputs1_loss: 0.0012\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1395 - n_outputs0_loss: 0.1384 - n_outputs1_loss: 0.0011\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.15487 to 0.13949, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.1476 - n_outputs0_loss: 0.1455 - n_outputs1_loss: 0.0021 - val_loss: 0.1395 - val_n_outputs0_loss: 0.1384 - val_n_outputs1_loss: 0.0011\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1343 - n_outputs0_loss: 0.1331 - n_outputs1_loss: 0.0012\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.13949 to 0.13425, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.1385 - n_outputs0_loss: 0.1367 - n_outputs1_loss: 0.0017 - val_loss: 0.1343 - val_n_outputs0_loss: 0.1331 - val_n_outputs1_loss: 0.0012\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1296 - n_outputs0_loss: 0.1285 - n_outputs1_loss: 0.0011\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.13425 to 0.12962, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.1284 - n_outputs0_loss: 0.1268 - n_outputs1_loss: 0.0016 - val_loss: 0.1296 - val_n_outputs0_loss: 0.1285 - val_n_outputs1_loss: 0.0011\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1251 - n_outputs0_loss: 0.1240 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.12962 to 0.12506, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.1216 - n_outputs0_loss: 0.1202 - n_outputs1_loss: 0.0014 - val_loss: 0.1251 - val_n_outputs0_loss: 0.1240 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1169 - n_outputs0_loss: 0.1159 - n_outputs1_loss: 0.0011\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.12506 to 0.11691, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.1128 - n_outputs0_loss: 0.1115 - n_outputs1_loss: 0.0013 - val_loss: 0.1169 - val_n_outputs0_loss: 0.1159 - val_n_outputs1_loss: 0.0011\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1156 - n_outputs0_loss: 0.1145 - n_outputs1_loss: 0.0011\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.11691 to 0.11562, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.1066 - n_outputs0_loss: 0.1054 - n_outputs1_loss: 0.0012 - val_loss: 0.1156 - val_n_outputs0_loss: 0.1145 - val_n_outputs1_loss: 0.0011\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1154 - n_outputs0_loss: 0.1143 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.11562 to 0.11536, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0986 - n_outputs0_loss: 0.0974 - n_outputs1_loss: 0.0011 - val_loss: 0.1154 - val_n_outputs0_loss: 0.1143 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1092 - n_outputs0_loss: 0.1082 - n_outputs1_loss: 9.9839e-04\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.11536 to 0.10915, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0916 - n_outputs0_loss: 0.0906 - n_outputs1_loss: 0.0011 - val_loss: 0.1092 - val_n_outputs0_loss: 0.1082 - val_n_outputs1_loss: 9.9839e-04\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1091 - n_outputs0_loss: 0.1081 - n_outputs1_loss: 9.7973e-04\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.10915 to 0.10907, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0867 - n_outputs0_loss: 0.0857 - n_outputs1_loss: 0.0010 - val_loss: 0.1091 - val_n_outputs0_loss: 0.1081 - val_n_outputs1_loss: 9.7973e-04\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.1029 - n_outputs0_loss: 0.1019 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.10907 to 0.10293, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0783 - n_outputs0_loss: 0.0773 - n_outputs1_loss: 0.0010 - val_loss: 0.1029 - val_n_outputs0_loss: 0.1019 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1013 - n_outputs0_loss: 0.1003 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.10293 to 0.10135, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0742 - n_outputs0_loss: 0.0732 - n_outputs1_loss: 9.6743e-04 - val_loss: 0.1013 - val_n_outputs0_loss: 0.1003 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0985 - n_outputs0_loss: 0.0974 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.10135 to 0.09846, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0677 - n_outputs0_loss: 0.0668 - n_outputs1_loss: 9.4914e-04 - val_loss: 0.0985 - val_n_outputs0_loss: 0.0974 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.0947 - n_outputs0_loss: 0.0937 - n_outputs1_loss: 9.9954e-04\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.09846 to 0.09466, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 56ms/step - loss: 0.0628 - n_outputs0_loss: 0.0619 - n_outputs1_loss: 9.1152e-04 - val_loss: 0.0947 - val_n_outputs0_loss: 0.0937 - val_n_outputs1_loss: 9.9954e-04\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0894 - n_outputs0_loss: 0.0884 - n_outputs1_loss: 9.6042e-04\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.09466 to 0.08937, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0575 - n_outputs0_loss: 0.0566 - n_outputs1_loss: 9.0378e-04 - val_loss: 0.0894 - val_n_outputs0_loss: 0.0884 - val_n_outputs1_loss: 9.6042e-04\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0874 - n_outputs0_loss: 0.0865 - n_outputs1_loss: 9.0003e-04\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.08937 to 0.08742, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0554 - n_outputs0_loss: 0.0546 - n_outputs1_loss: 8.9132e-04 - val_loss: 0.0874 - val_n_outputs0_loss: 0.0865 - val_n_outputs1_loss: 9.0003e-04\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.0873 - n_outputs0_loss: 0.0863 - n_outputs1_loss: 9.9919e-04\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.08742 to 0.08735, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0506 - n_outputs0_loss: 0.0497 - n_outputs1_loss: 8.7480e-04 - val_loss: 0.0873 - val_n_outputs0_loss: 0.0863 - val_n_outputs1_loss: 9.9919e-04\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0859 - n_outputs0_loss: 0.0849 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.08735 to 0.08587, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0498 - n_outputs0_loss: 0.0489 - n_outputs1_loss: 8.7537e-04 - val_loss: 0.0859 - val_n_outputs0_loss: 0.0849 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0793 - n_outputs0_loss: 0.0784 - n_outputs1_loss: 9.4177e-04\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.08587 to 0.07932, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0449 - n_outputs0_loss: 0.0441 - n_outputs1_loss: 8.6681e-04 - val_loss: 0.0793 - val_n_outputs0_loss: 0.0784 - val_n_outputs1_loss: 9.4177e-04\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.0814 - n_outputs0_loss: 0.0805 - n_outputs1_loss: 9.9320e-04\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.07932\n",
            "97/97 [==============================] - 5s 51ms/step - loss: 0.0427 - n_outputs0_loss: 0.0419 - n_outputs1_loss: 8.5820e-04 - val_loss: 0.0814 - val_n_outputs0_loss: 0.0805 - val_n_outputs1_loss: 9.9320e-04\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0870 - n_outputs0_loss: 0.0859 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.07932\n",
            "97/97 [==============================] - 5s 52ms/step - loss: 0.0410 - n_outputs0_loss: 0.0401 - n_outputs1_loss: 8.5544e-04 - val_loss: 0.0870 - val_n_outputs0_loss: 0.0859 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0777 - n_outputs0_loss: 0.0767 - n_outputs1_loss: 9.7710e-04\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.07932 to 0.07770, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0383 - n_outputs0_loss: 0.0374 - n_outputs1_loss: 8.5014e-04 - val_loss: 0.0777 - val_n_outputs0_loss: 0.0767 - val_n_outputs1_loss: 9.7710e-04\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0755 - n_outputs0_loss: 0.0746 - n_outputs1_loss: 9.8293e-04\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.07770 to 0.07554, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0369 - n_outputs0_loss: 0.0361 - n_outputs1_loss: 8.3945e-04 - val_loss: 0.0755 - val_n_outputs0_loss: 0.0746 - val_n_outputs1_loss: 9.8293e-04\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0824 - n_outputs0_loss: 0.0814 - n_outputs1_loss: 9.9883e-04\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.07554\n",
            "97/97 [==============================] - 5s 52ms/step - loss: 0.0350 - n_outputs0_loss: 0.0342 - n_outputs1_loss: 8.4758e-04 - val_loss: 0.0824 - val_n_outputs0_loss: 0.0814 - val_n_outputs1_loss: 9.9883e-04\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0752 - n_outputs0_loss: 0.0742 - n_outputs1_loss: 9.6122e-04\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.07554 to 0.07516, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0334 - n_outputs0_loss: 0.0326 - n_outputs1_loss: 8.4319e-04 - val_loss: 0.0752 - val_n_outputs0_loss: 0.0742 - val_n_outputs1_loss: 9.6122e-04\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.0773 - n_outputs0_loss: 0.0762 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.07516\n",
            "97/97 [==============================] - 5s 52ms/step - loss: 0.0323 - n_outputs0_loss: 0.0315 - n_outputs1_loss: 8.4006e-04 - val_loss: 0.0773 - val_n_outputs0_loss: 0.0762 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0722 - n_outputs0_loss: 0.0712 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.07516 to 0.07221, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0313 - n_outputs0_loss: 0.0305 - n_outputs1_loss: 8.4255e-04 - val_loss: 0.0722 - val_n_outputs0_loss: 0.0712 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0696 - n_outputs0_loss: 0.0686 - n_outputs1_loss: 9.9427e-04\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.07221 to 0.06961, saving model to /content/d2/models/lin_aug2_collab.h5\n",
            "97/97 [==============================] - 5s 55ms/step - loss: 0.0290 - n_outputs0_loss: 0.0282 - n_outputs1_loss: 8.4686e-04 - val_loss: 0.0696 - val_n_outputs0_loss: 0.0686 - val_n_outputs1_loss: 9.9427e-04\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.0725 - n_outputs0_loss: 0.0715 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.06961\n",
            "97/97 [==============================] - 5s 52ms/step - loss: 0.0285 - n_outputs0_loss: 0.0276 - n_outputs1_loss: 8.4281e-04 - val_loss: 0.0725 - val_n_outputs0_loss: 0.0715 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0721 - n_outputs0_loss: 0.0710 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.06961\n",
            "97/97 [==============================] - 5s 52ms/step - loss: 0.0306 - n_outputs0_loss: 0.0298 - n_outputs1_loss: 8.4576e-04 - val_loss: 0.0721 - val_n_outputs0_loss: 0.0710 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.0707 - n_outputs0_loss: 0.0696 - n_outputs1_loss: 0.0011\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.06961\n",
            "97/97 [==============================] - 5s 52ms/step - loss: 0.0281 - n_outputs0_loss: 0.0273 - n_outputs1_loss: 8.4564e-04 - val_loss: 0.0707 - val_n_outputs0_loss: 0.0696 - val_n_outputs1_loss: 0.0011\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.0733 - n_outputs0_loss: 0.0724 - n_outputs1_loss: 9.2958e-04\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.06961\n",
            "97/97 [==============================] - 5s 52ms/step - loss: 0.0266 - n_outputs0_loss: 0.0258 - n_outputs1_loss: 8.4682e-04 - val_loss: 0.0733 - val_n_outputs0_loss: 0.0724 - val_n_outputs1_loss: 9.2958e-04\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.0776 - n_outputs0_loss: 0.0766 - n_outputs1_loss: 0.0010\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.06961\n",
            "97/97 [==============================] - 5s 52ms/step - loss: 0.0268 - n_outputs0_loss: 0.0259 - n_outputs1_loss: 8.5245e-04 - val_loss: 0.0776 - val_n_outputs0_loss: 0.0766 - val_n_outputs1_loss: 0.0010\n",
            "Epoch 00036: early stopping\n",
            "Training completed in 0:03:28.\n",
            "\n",
            "\n",
            "----------- Best Eval Loss :0.069615 ---------\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5YxpLLN6LCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOX3AVCfhnOi",
        "colab_type": "text"
      },
      "source": [
        "# Update Models via GitHub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_0FTr1I8KN9",
        "colab_type": "text"
      },
      "source": [
        "**Initialize Folder Models in GitHub**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh7e_phlZhca",
        "colab_type": "code",
        "outputId": "adf4a10b-846d-46b2-84fb-f4c6bb4f3e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "%cd /content/d2/models\n",
        "!git config --global user.name \"JuanFuriaz\"\n",
        "!git config --global user.email \"juan.furiaz88@gmail.com\"\n",
        "!git config --global credential.helper 'cache --timeout=100800'\n",
        "!git config --global user.password \"oaDCpWTF2019!\"\n",
        "!git init\n",
        "#!git add *\n",
        "#!git commit -m \"initialize in cloud\"\n",
        "!git remote add origin https://JuanFuriaz:oaDCpWTF2019!@github.com/JuanFuriaz/donkey_car_models.git\n",
        "!git pull origin master --allow-unrelated-histories"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/d2/models\n",
            "Initialized empty Git repository in /content/d2/models/.git/\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 112 (delta 5), reused 25 (delta 2), pack-reused 84\u001b[K\n",
            "Receiving objects: 100% (112/112), 85.23 MiB | 38.03 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n",
            "From https://github.com/JuanFuriaz/donkey_car_models\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxmzccwu8TOK",
        "colab_type": "text"
      },
      "source": [
        "**Upload after Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWkuGJQb8QX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/d2/models\n",
        "!git add *\n",
        "!git commit -m \"model commit\"\n",
        "!git push -u origin master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0qxkJNfkQ0x",
        "colab_type": "text"
      },
      "source": [
        "# Removing Folders or files via GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES945FZqjiSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip /content/d2/data/data.zip -d /content/d2/\n",
        "\n",
        "!rm -r /content/d2/data/data.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo-7g_dMLvxR",
        "colab_type": "text"
      },
      "source": [
        "# Creating Keras HEATMAP video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHT1sAXjv4ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Convolution2D\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from glob import glob\n",
        "from keras import backend as K\n",
        "#plt.rcParams['animation.ffmpeg_path'] = '/home/jm/bin/ffmpeg' # explicit path for finding ffmpeg in my computer\n",
        "\n",
        "\n",
        "def compute_visualisation_mask(img, functor, layers_kernels, layers_strides):\n",
        "    activations = functor([np.array([img])])\n",
        "    upscaled_activation = np.ones((3, 6))\n",
        "    for layer in [4, 3, 2, 1, 0]:\n",
        "        averaged_activation = np.mean(activations[layer], axis=3).squeeze(axis=0) * upscaled_activation\n",
        "        if layer > 0:\n",
        "            output_shape = (activations[layer - 1].shape[1], activations[layer - 1].shape[2])\n",
        "        else:\n",
        "            output_shape = (120, 160)\n",
        "        x = tf.constant(\n",
        "            np.reshape(averaged_activation, (1,averaged_activation.shape[0],averaged_activation.shape[1],1)),\n",
        "            tf.float32\n",
        "        )\n",
        "        conv = tf.nn.conv2d_transpose(\n",
        "            x, layers_kernels[layer],\n",
        "            output_shape=(1,output_shape[0],output_shape[1], 1),\n",
        "            strides=layers_strides[layer],\n",
        "            padding='VALID'\n",
        "        )\n",
        "        with tf.Session() as session:\n",
        "            result = session.run(conv)\n",
        "        upscaled_activation = np.reshape(result, output_shape)\n",
        "    final_visualisation_mask = upscaled_activation\n",
        "    return (final_visualisation_mask - np.min(final_visualisation_mask))/(np.max(final_visualisation_mask) - np.min(final_visualisation_mask))\n",
        "\n",
        "\n",
        "def save_movie_mp4(image_array, video_name = \"example.mp4\"):\n",
        "    writer = animation.FFMpegFileWriter(fps=20, metadata=dict(artist='Me'), bitrate=1800)\n",
        "    dpi = 72.0\n",
        "    xpixels, ypixels = image_array[0].shape[0], image_array[0].shape[1]\n",
        "    fig = plt.figure(figsize=(ypixels/dpi, xpixels/dpi), dpi=dpi)\n",
        "    im = plt.figimage(image_array[0])\n",
        "\n",
        "\n",
        "    def animate(i):\n",
        "        im.set_array(image_array[i])\n",
        "        return (im,)\n",
        "\n",
        "    plt.show()\n",
        "    ani = animation.FuncAnimation(fig, animate, frames=len(image_array))\n",
        "    ani.save(video_name, writer=writer)\n",
        "\n",
        "\n",
        "def get_video_array(video_limit=500, data_path = 'my/path/to/imgs/*.jpg', functor= None, layers_kernels = None, layers_strides = None):\n",
        "\n",
        "    def numericalSort(value):\n",
        "        parts = value.split(\"/\")[-1]\n",
        "        parts = int(parts.split(\"_\")[0])\n",
        "        return parts\n",
        "\n",
        "    imgs = []\n",
        "    alpha = 0.004\n",
        "    beta = 1.0 - alpha\n",
        "    counter = 0\n",
        "    for path in sorted(glob(data_path), key=numericalSort):\n",
        "        img = cv2.imread(path)\n",
        "        salient_mask = compute_visualisation_mask(img, functor, layers_kernels, layers_strides)\n",
        "        salient_mask_stacked = np.dstack((salient_mask,salient_mask))\n",
        "        salient_mask_stacked = np.dstack((salient_mask_stacked,salient_mask))\n",
        "        blend = cv2.addWeighted(img.astype('float32'), alpha, salient_mask_stacked, beta, 0.0)\n",
        "        imgs.append(blend)\n",
        "        counter += 1\n",
        "        if video_limit is not None:\n",
        "            if counter >= video_limit:\n",
        "                return imgs\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def get_keras_functor(model_path=\"my/path/to/model.h5\"):\n",
        "    \"\"\"\n",
        "    Create CNN-model structure for Heatmap\n",
        "    \"\"\"\n",
        "    custom_objects = {\"GlorotUniform\": tf.keras.initializers.glorot_uniform}\n",
        "    model = load_model(model_path, custom_objects)\n",
        "\n",
        "    img_in = Input(shape=(120, 160, 3), name='img_in')\n",
        "    x = img_in\n",
        "    x = Convolution2D(24, (5, 5), strides=(2, 2), activation='relu', name='conv2d_1')(x)\n",
        "    x = Convolution2D(32, (5, 5), strides=(2, 2), activation='relu', name='conv2d_2')(x)\n",
        "    x = Convolution2D(64, (5, 5), strides=(2, 2), activation='relu', name='conv2d_3')(x)\n",
        "    x = Convolution2D(64, (3, 3), strides=(2, 2), activation='relu', name='conv2d_4')(x)\n",
        "    conv_5 = Convolution2D(64, (3, 3), strides=(1, 1), activation='relu', name='conv2d_5')(x)\n",
        "    convolution_part = Model(inputs=[img_in], outputs=[conv_5])\n",
        "\n",
        "    for layer_num in ('1', '2', '3', '4', '5'):\n",
        "        convolution_part.get_layer('conv2d_' + layer_num).set_weights(\n",
        "            model.get_layer('conv2d_' + layer_num).get_weights())\n",
        "    inp = convolution_part.input  # input placeholder\n",
        "    outputs = [layer.output for layer in convolution_part.layers][1:]  # all layer outputs\n",
        "    functor = K.function([inp], outputs)\n",
        "    return functor\n",
        "\n",
        "\n",
        "def main(video_limit = 100, data_path = 'my/path/to/imgs/*.jpg', model_path=\"my/path/to/model.h5\", video_name = \"example.mp4\"):\n",
        "    functor = get_keras_functor(model_path= model_path)\n",
        "    kernel_3x3 = tf.constant(np.array([\n",
        "        [[[1]], [[1]], [[1]]],\n",
        "        [[[1]], [[1]], [[1]]],\n",
        "        [[[1]], [[1]], [[1]]]\n",
        "    ]), tf.float32)\n",
        "    kernel_5x5 = tf.constant(np.array([\n",
        "        [[[1]], [[1]], [[1]], [[1]], [[1]]],\n",
        "        [[[1]], [[1]], [[1]], [[1]], [[1]]],\n",
        "        [[[1]], [[1]], [[1]], [[1]], [[1]]],\n",
        "        [[[1]], [[1]], [[1]], [[1]], [[1]]],\n",
        "        [[[1]], [[1]], [[1]], [[1]], [[1]]]\n",
        "    ]), tf.float32)\n",
        "    layers_kernels = {4: kernel_3x3, 3: kernel_3x3, 2: kernel_5x5, 1: kernel_5x5, 0: kernel_5x5}\n",
        "    layers_strides = {4: [1, 1, 1, 1], 3: [1, 2, 2, 1], 2: [1, 2, 2, 1], 1: [1, 2, 2, 1], 0: [1, 2, 2, 1]}\n",
        "    imgs = get_video_array(video_limit= video_limit, data_path = data_path, functor= functor, layers_kernels = layers_kernels, layers_strides = layers_strides)\n",
        "    save_movie_mp4(imgs,  video_name)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(700, 'd2/data/tub_2_19-12-22/*.jpg',\"d2/models/mod_lin_1.h5\", \"lin_mod_tub2_700.mp4\" )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}